{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "SKIP_FILES = set(['cmds'])\n",
      "\n",
      "# Method to read all files from a directory\n",
      "def read_files(path):\n",
      "  for root, dir_names, file_names in os.walk(path):\n",
      "    for path in dir_names:\n",
      "      read_files(os.path.join(root, path))\n",
      "    for file_name in file_names:\n",
      "      if file_name not in SKIP_FILES:\n",
      "        file_path = os.path.join(root, file_name)\n",
      "        if os.path.isfile(file_path):\n",
      "          lines = []\n",
      "          f = open(file_path)\n",
      "          for line in f:\n",
      "            lines.append(line)\n",
      "          f.close()\n",
      "          yield file_path, lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the method to load data from files\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "def build_data_frame(path, classification):\n",
      "  data_frame = pd.DataFrame({'text': [], 'class': []})\n",
      "  for file_name, lines in read_files(path):\n",
      "    for line in lines:\n",
      "      data_frame = data_frame.append(\n",
      "        pd.DataFrame({'text': [line], 'class': [classification]}))\n",
      "  data_frame.drop_duplicates(cols=['text'])\n",
      "  return data_frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Learning Style\n",
      "\n",
      "## Supervised Learning: \n",
      "Input data is called training data and has a known label or result such as spam/not-spam or a stock price at a time. A model is prepared through a training process where it is required to make predictions and is corrected when those predictions are wrong. The training process continues until the model achieves a desired level of accuracy on the training data. Example problems are classification and regression. Example algorithms are Logistic Regression and the Back Propagation Neural Network.\n",
      "\n",
      "## Unsupervised Learning: \n",
      "Input data is not labelled and does not have a known result. A model is prepared by deducing structures present in the input data. Example problems are association rule learning and clustering. Example algorithms are the Apriori algorithm and k-means.\n",
      "\n",
      "source: http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/\n",
      "\n",
      "# Data\n",
      "\n",
      "## Categorical\n",
      "\n",
      "Categorical variables represent types of data which may be divided into groups. Examples of categorical variables are race, sex, age group, and educational level. While the latter two variables may also be considered in a numerical manner by using exact values for age and highest grade completed, it is often more informative to categorize such variables into a relatively small number of groups.\n",
      "\n",
      "## Continuous\n",
      "\n",
      "Continuous data is information that can be measured on a continuum or scale. Continuous data can have almost any numeric value and can be meaningfully subdivided into finer and finer increments, depending upon the precision of the measurement system.\n",
      "As opposed to discrete data like good or bad, off or on, etc., continuous data can be recorded at many different points (length, size, width, time, temperature, cost, etc.).\n",
      "Continuous data is data that can be measured and broken down into smaller parts and still have meaning. Money, temperature and time are continous.Volume (like volume of water or air) and size are continuous data.\n",
      "\n",
      "\n",
      "<img src=\"files/types.png\">"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Definind data source\n",
      "HAM = 0\n",
      "SPAM = 1\n",
      "\n",
      "SOURCES = [\n",
      "           ('data/spam', SPAM),\n",
      "           ('data/ham', HAM)\n",
      "           ]\n",
      "\n",
      "# Loading data\n",
      "\n",
      "data_frames = []\n",
      "for path, classification in SOURCES:\n",
      "  new_df = build_data_frame(path, classification)\n",
      "  data_frames.append(new_df)\n",
      "\n",
      "data = pd.concat(data_frames)\n",
      "data['index'] = np.arange(0, len(data))\n",
      "data = data.reindex(numpy.random.permutation(data.index))\n",
      "\n",
      "print data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   class                                               text  index\n",
        "0      1  \u0000\u0000\u0000\u0001Bud1\u0000\u0000\u0010\u0000\u0000\u0000\b\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u0000%\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...      0\n",
        "0      1  #marvel #hachette #graphicnovel #theamazingspi...      1\n",
        "0      1  RT @GabbysQuilts: http://t.co/OxKXzMrMlI #circ...      2\n",
        "0      1  RT @2bproductive: 10% #Discount on #Books RARA...      3\n",
        "0      1  #vegan Cibaderm #NonGMO #hemp oil beauty produ...      4\n",
        "\n",
        "[5 rows x 3 columns]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Features + Model\n",
      "\n",
      "## Feature extraction\n",
      "* Work with the data to enrich the features\n",
      "* One of the most important steps when training a model\n",
      "* Feature Selection\n",
      "\n",
      "## Model\n",
      "* Choose the model that best fits your data\n",
      "* Experiment with different models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "bayes_pipeline = Pipeline([\n",
      "  ('vectorizer',  CountVectorizer(decode_error='ignore')),\n",
      "  ('tfidf_transformer',  TfidfTransformer()),\n",
      "  ('classifier',  MultinomialNB()) ])\n",
      "  #('classifier',  LinearSVC()) ])\n",
      "\n",
      "bayes_pipeline.fit(numpy.asarray(data['text']), numpy.asarray(data['class']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error='ignore',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1),...         use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cross Validation\n",
      "\n",
      "## K-fold\n",
      "* Better way to evaluate the model accuracy\n",
      "* Training set\n",
      "* Test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import metrics\n",
      "\n",
      "k_fold = KFold(n=len(data), n_folds=6, indices=False)\n",
      "b_scores, svc_scores = [], []\n",
      "\n",
      "print 'Bayes score:'\n",
      "for train_indices, test_indices in k_fold:\n",
      "  train_text = numpy.asarray(data[train_indices]['text'])\n",
      "  train_y    = numpy.asarray(data[train_indices]['class'])\n",
      "\n",
      "  test_text  = numpy.asarray(data[test_indices]['text'])\n",
      "  test_y     = numpy.asarray(data[test_indices]['class'])\n",
      "\n",
      "  bayes_pipeline.fit(train_text, train_y)\n",
      "  score = bayes_pipeline.score(test_text, test_y)\n",
      "  b_scores.append(score)\n",
      "  pred_y = bayes_pipeline.predict(test_text)\n",
      "  print metrics.confusion_matrix(test_y, pred_y)\n",
      "\n",
      "  print \n",
      "\n",
      "score = sum(b_scores) / len(b_scores)\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bayes score:\n",
        "[[   0    0]\n",
        " [ 449 3314]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[[   0    0]\n",
        " [ 433 3329]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[[   0    0]\n",
        " [ 523 3239]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[[ 583  145]\n",
        " [1531 1503]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[[1380 2382]\n",
        " [   0    0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[[ 945 2817]\n",
        " [   0    0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "0.633179129882\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}